{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Python Runtime Type Validation Libraries\n",
    "\n",
    "## Test Functions\n",
    "Let's first define a two type annotated test functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_larger_1(num_dict: dict[str, float]) -> dict[str, bool]:\n",
    "    \"\"\"Translates float values of the input dictionary into bool in the output dict\n",
    "    depending on whether the value is > 1 or not.\"\"\"\n",
    "    try:\n",
    "        return {key: num_dict[key] > 1 for key in num_dict}\n",
    "    except:\n",
    "        return {}\n",
    "\n",
    "\n",
    "def is_larger_1_should_fail(num_dict: dict[str, float]) -> dict[str, bool]:\n",
    "    \"\"\"It should translates float values of the input dictionary into bool in the output dict\n",
    "    depending on whether the value is > 1 or not. However, the output values are 1 if\n",
    "    higher and 0 if lower or equal to 1. (This 1/0 representation could be coerced into\n",
    "    True/False.)\"\"\"\n",
    "    try:\n",
    "        return {key: int(num_dict[key] > 1) for key in num_dict}\n",
    "    except:\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both functions are doing basically the same thing:\n",
    "\n",
    "They accept a dictionary with str keys and float values and check for each value whether\n",
    "it is larger 1. They are both intended to return a dictionary with boolean values indicating\n",
    "the results.\n",
    "\n",
    "However, the second function formats the output dict wrong. It is using 1/0 integers\n",
    "instead of True/False for the values. Of course, the 1/0 encoding could be easily\n",
    "coerced into a boolean representation, however, a strict type checker should throw an\n",
    "exception instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data\n",
    "Let's next define some test data that could be used with the above functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = {\"a\": 1.2, \"b\": 34.56}\n",
    "test_dict_should_fail = {\"a\": \"1.2\", \"b\": \"34.56\"}\n",
    "test_dict_should_definitely_fail = {\"a\": lambda x: x * 2, \"b\": None}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first example is alright and complies with the type restrictions of the \n",
    "functions' input argument.\n",
    "\n",
    "The second example uses int instead of float values. A smart parser could translate\n",
    "int values into floats, however, a strict type checker should throw an exception.\n",
    "\n",
    "The third option is definitely wrong as there is no intuitive way to translate the\n",
    "given values into floats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Cases\n",
    "Let's combine the test functions and test data into a couple of test cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Case 1 (should pass):\n",
      "{'a': True, 'b': True}\n",
      "\n",
      "\n",
      ">>> Case 2 (should fail):\n",
      "{}\n",
      "\n",
      "\n",
      ">>> Case 3 (should fail):\n",
      "{'a': 1, 'b': 1}\n",
      "\n",
      "\n",
      ">>> Case 4 (should fail):\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "from typing import Callable\n",
    "import traceback\n",
    "\n",
    "def run_test_cases(func_ok: Callable, func_fail: Callable) -> None:\n",
    "    \"\"\"Run test cases with provided functions.\"\"\"\n",
    "\n",
    "    print(\">>> Case 1 (should pass):\")\n",
    "    try:\n",
    "        print(func_ok(test_dict))\n",
    "    except:\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "    print(\"\\n\\n>>> Case 2 (should fail):\")\n",
    "    try:\n",
    "        print(func_ok(test_dict_should_fail))\n",
    "    except:\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "    print(\"\\n\\n>>> Case 3 (should fail):\")\n",
    "    try:\n",
    "        print(func_fail(test_dict))\n",
    "    except:\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "    print(\"\\n\\n>>> Case 4 (should fail):\")\n",
    "    try:\n",
    "        print(func_ok(test_dict_should_definitely_fail))\n",
    "    except:\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "\n",
    "run_test_cases(is_larger_1, is_larger_1_should_fail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Except for Case 1, all cases should fail. Either because the return value of the function\n",
    "is not correct or the input test data is wrong.\n",
    "\n",
    "Because we have not applied any type validation utility, yet, every test passes without\n",
    "complains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with Pydantic Decorator\n",
    "Now let's apply the `validate_arguments` decorator utility from the pydantic library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import validate_arguments\n",
    "\n",
    "@validate_arguments\n",
    "def pd_is_larger_1(num_dict: dict[str, float]) -> dict[str, bool]:\n",
    "    \"\"\"Translates float values of the input dictionary into bool in the output dict\n",
    "    depending on whether the value is > 1 or not.\"\"\"\n",
    "    try:\n",
    "        return {key: num_dict[key] > 1 for key in num_dict}\n",
    "    except:\n",
    "        return {}\n",
    "\n",
    "@validate_arguments\n",
    "def pd_is_larger_1_should_fail(num_dict: dict[str, float]) -> dict[str, bool]:\n",
    "    \"\"\"It should translates float values of the input dictionary into bool in the output dict\n",
    "    depending on whether the value is > 1 or not. However, the output values are 1 if\n",
    "    higher and 0 if lower or equal to 1. (This 1/0 representation could be coerced into\n",
    "    True/False.)\"\"\"\n",
    "    try:\n",
    "        return {key: int(num_dict[key] > 1) for key in num_dict}\n",
    "    except:\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's run the tests with the pydantic-validated functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Case 1 (should pass):\n",
      "{'a': True, 'b': True}\n",
      "\n",
      "\n",
      ">>> Case 2 (should fail):\n",
      "{'a': True, 'b': True}\n",
      "\n",
      "\n",
      ">>> Case 3 (should fail):\n",
      "{'a': 1, 'b': 1}\n",
      "\n",
      "\n",
      ">>> Case 4 (should fail):\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15302/313806667.py\", line 27, in run_test_cases\n",
      "    print(func_ok(test_dict_should_definitely_fail))\n",
      "  File \"pydantic/decorator.py\", line 40, in pydantic.decorator.validate_arguments.validate.wrapper_function\n",
      "  File \"pydantic/decorator.py\", line 133, in pydantic.decorator.ValidatedFunction.call\n",
      "  File \"pydantic/decorator.py\", line 130, in pydantic.decorator.ValidatedFunction.init_model_instance\n",
      "  File \"pydantic/main.py\", line 331, in pydantic.main.BaseModel.__init__\n",
      "pydantic.error_wrappers.ValidationError: 2 validation errors for PdIsLarger1\n",
      "num_dict -> a\n",
      "  value is not a valid float (type=type_error.float)\n",
      "num_dict -> b\n",
      "  none is not an allowed value (type=type_error.none.not_allowed)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_cases(pd_is_larger_1, pd_is_larger_1_should_fail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, only the completely wrong test case is failing. The rest is passing and \n",
    "working just fine. The reason is pydantic is primarily a parsing library that tries to \n",
    "coerce input data into the expected type. Validation is only a side effect of that and\n",
    "only happens on the coerced data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with Pydantic Decorator and Strict Types\n",
    "If you want to use pydantic in strict mode, there is the option of using the \n",
    "pydantic-specific \"Strict\" typehints. For that we have to redefine the functions using\n",
    "the special types: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pydantic import StrictStr, StrictFloat, StrictBool\n",
    "\n",
    "\n",
    "@validate_arguments\n",
    "def spd_is_larger_1(num_dict: dict[StrictStr, StrictFloat]) -> dict[StrictStr, StrictBool]:\n",
    "    \"\"\"Translates float values of the input dictionary into bool in the output dict\n",
    "    depending on whether the value is > 1 or not.\"\"\"\n",
    "    try:\n",
    "        return {key: num_dict[key] > 1 for key in num_dict}\n",
    "    except:\n",
    "        return {}\n",
    "\n",
    "\n",
    "@validate_arguments\n",
    "def spd_is_larger_1_should_fail(\n",
    "    num_dict: dict[StrictStr, StrictFloat]\n",
    ") -> dict[StrictStr, StrictBool]:\n",
    "    \"\"\"It should translates float values of the input dictionary into bool in the output dict\n",
    "    depending on whether the value is > 1 or not. However, the output values are 1 if\n",
    "    higher and 0 if lower or equal to 1. (This 1/0 representation could be coerced into\n",
    "    True/False.)\"\"\"\n",
    "    try:\n",
    "        return {key: int(num_dict[key] > 1) for key in num_dict}\n",
    "    except:\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    " Copyright 2022 Universität Tübingen, DKFZ and EMBL\n",
    " for the German Human Genome-Phenome Archive (GHGA)\n",
    " \n",
    " Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    " you may not use this file except in compliance with the License.\n",
    " You may obtain a copy of the License at\n",
    " \n",
    "     http://www.apache.org/licenses/LICENSE-2.0\n",
    " \n",
    " Unless required by applicable law or agreed to in writing, software\n",
    " distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    " WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    " See the License for the specific language governing permissions and\n",
    " limitations under the License.\n",
    "-->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And run the tests again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Case 1 (should pass):\n",
      "{'a': True, 'b': True}\n",
      "\n",
      "\n",
      ">>> Case 2 (should fail):\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15302/313806667.py\", line 15, in run_test_cases\n",
      "    print(func_ok(test_dict_should_fail))\n",
      "  File \"pydantic/decorator.py\", line 40, in pydantic.decorator.validate_arguments.validate.wrapper_function\n",
      "  File \"pydantic/decorator.py\", line 133, in pydantic.decorator.ValidatedFunction.call\n",
      "  File \"pydantic/decorator.py\", line 130, in pydantic.decorator.ValidatedFunction.init_model_instance\n",
      "  File \"pydantic/main.py\", line 331, in pydantic.main.BaseModel.__init__\n",
      "pydantic.error_wrappers.ValidationError: 2 validation errors for SpdIsLarger1\n",
      "num_dict -> a\n",
      "  value is not a valid float (type=type_error.float)\n",
      "num_dict -> b\n",
      "  value is not a valid float (type=type_error.float)\n",
      "\n",
      "\n",
      "\n",
      ">>> Case 3 (should fail):\n",
      "{'a': 1, 'b': 1}\n",
      "\n",
      "\n",
      ">>> Case 4 (should fail):\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15302/313806667.py\", line 27, in run_test_cases\n",
      "    print(func_ok(test_dict_should_definitely_fail))\n",
      "  File \"pydantic/decorator.py\", line 40, in pydantic.decorator.validate_arguments.validate.wrapper_function\n",
      "  File \"pydantic/decorator.py\", line 133, in pydantic.decorator.ValidatedFunction.call\n",
      "  File \"pydantic/decorator.py\", line 130, in pydantic.decorator.ValidatedFunction.init_model_instance\n",
      "  File \"pydantic/main.py\", line 331, in pydantic.main.BaseModel.__init__\n",
      "pydantic.error_wrappers.ValidationError: 2 validation errors for SpdIsLarger1\n",
      "num_dict -> a\n",
      "  value is not a valid float (type=type_error.float)\n",
      "num_dict -> b\n",
      "  none is not an allowed value (type=type_error.none.not_allowed)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_cases(spd_is_larger_1, spd_is_larger_1_should_fail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was almost what we want. However, Case 3 is still not failing even though it should.\n",
    "The reason is that the pydantic decorator only checks input arguments not the output\n",
    "types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with Typeguard Decorator\n",
    "Again we need to decorate our defined funtions with the utility provided by Typeguard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typeguard import typechecked\n",
    "\n",
    "@typechecked\n",
    "def tg_is_larger_1(num_dict: dict[str, float]) -> dict[str, bool]:\n",
    "    \"\"\"Translates float values of the input dictionary into bool in the output dict\n",
    "    depending on whether the value is > 1 or not.\"\"\"\n",
    "    try:\n",
    "        return {key: num_dict[key] > 1 for key in num_dict}\n",
    "    except:\n",
    "        return {}\n",
    "\n",
    "@typechecked\n",
    "def tg_is_larger_1_should_fail(num_dict: dict[str, float]) -> dict[str, bool]:\n",
    "    \"\"\"It should translates float values of the input dictionary into bool in the output dict\n",
    "    depending on whether the value is > 1 or not. However, the output values are 1 if\n",
    "    higher and 0 if lower or equal to 1. (This 1/0 representation could be coerced into\n",
    "    True/False.)\"\"\"\n",
    "    try:\n",
    "        return {key: int(num_dict[key] > 1) for key in num_dict}\n",
    "    except:\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Case 1 (should pass):\n",
      "{'a': True, 'b': True}\n",
      "\n",
      "\n",
      ">>> Case 2 (should fail):\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15302/313806667.py\", line 15, in run_test_cases\n",
      "    print(func_ok(test_dict_should_fail))\n",
      "  File \"/home/vscode/.local/lib/python3.9/site-packages/typeguard/__init__.py\", line 1032, in wrapper\n",
      "    check_argument_types(memo)\n",
      "  File \"/home/vscode/.local/lib/python3.9/site-packages/typeguard/__init__.py\", line 875, in check_argument_types\n",
      "    raise TypeError(*exc.args) from None\n",
      "TypeError: type of argument \"num_dict\"['a'] must be either float or int; got str instead\n",
      "\n",
      "\n",
      "\n",
      ">>> Case 3 (should fail):\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15302/313806667.py\", line 21, in run_test_cases\n",
      "    print(func_fail(test_dict))\n",
      "  File \"/home/vscode/.local/lib/python3.9/site-packages/typeguard/__init__.py\", line 1037, in wrapper\n",
      "    raise TypeError(*exc.args) from None\n",
      "TypeError: type of the return value['a'] must be bool; got int instead\n",
      "\n",
      "\n",
      "\n",
      ">>> Case 4 (should fail):\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15302/313806667.py\", line 27, in run_test_cases\n",
      "    print(func_ok(test_dict_should_definitely_fail))\n",
      "  File \"/home/vscode/.local/lib/python3.9/site-packages/typeguard/__init__.py\", line 1032, in wrapper\n",
      "    check_argument_types(memo)\n",
      "  File \"/home/vscode/.local/lib/python3.9/site-packages/typeguard/__init__.py\", line 875, in check_argument_types\n",
      "    raise TypeError(*exc.args) from None\n",
      "TypeError: type of argument \"num_dict\"['a'] must be either float or int; got function instead\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_test_cases(tg_is_larger_1, tg_is_larger_1_should_fail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is exactly the behavior we want."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
